{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xiangcheng/Documents/notebooks/time-series'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-71be4bfdee8d>, line 105)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-71be4bfdee8d>\"\u001b[0;36m, line \u001b[0;32m105\u001b[0m\n\u001b[0;31m    model _lstm.add(Activation(self.paras.model['activation'][idx]))\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn import preprocessing\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt  # http://matplotlib.org/examples/pylab_examples/subplots_demo.html\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quandl\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import History\n",
    "\n",
    "class rnn_lstm(object):\n",
    "    def __init__(self, paras):\n",
    "        self.paras = paras\n",
    "        self.df = None\n",
    "\n",
    "    def get_file_id(self):\n",
    "        return (self.paras.identify + '_' + str(self.paras.window_len) + '_' + str(self.paras.pred_len) + '_'\n",
    "                + str(self.paras.features) + '_' + str(self.paras.start_date) + '_' + str(self.paras.end_date)\n",
    "                + '_' + str(self.paras.model['hidden_layers']) + '_' + str(self.paras.model['dropout']) + '_'\n",
    "                + str(self.paras.model['activation']))\n",
    "\n",
    "    def get_save_directory(self):\n",
    "        if self.paras.save == False:\n",
    "            return ''\n",
    "\n",
    "        dir = './history/'\n",
    "        if os.path.exists(dir) == False:\n",
    "            os.makedirs(dir)\n",
    "        file_id = self.get_file_id()\n",
    "        save_folder = str(dir) + str(file_id)\n",
    "        os.makedirs(save_folder)\n",
    "        return (save_folder + '/')\n",
    "\n",
    "    def preprocessing_data_by_row(self, data):\n",
    "        '''\n",
    "        data: N*M np.array\n",
    "        N: sample\n",
    "        M: features\n",
    "        data_T: M*N\n",
    "        data_T_scale: scaler for column by column, M*N\n",
    "        data_T_scale_T: N*M\n",
    "        '''\n",
    "        if data.size == 0:\n",
    "            return data, None\n",
    "\n",
    "        data_T = data.transpose()\n",
    "        if self.paras.preproc_scaler == 'standard_scaler':\n",
    "            scaler = preprocessing.StandardScaler().fit(data_T)\n",
    "        else:  # FIXME\n",
    "            scaler = preprocessing.StandardScaler().fit(data_T)\n",
    "        data_T_scale = scaler.transform(data_T)\n",
    "        data_T_scale_T = data_T_scale.transpose()\n",
    "        return data_T_scale_T, scaler\n",
    "\n",
    "    def divide_into_price_volume(self, df):\n",
    "        '''\n",
    "        df.columns = [..., o_-10_d,h_-10_d,l_-10_d,c_-10_d,v_-10_d,...]\n",
    "        return [...,o_-10_d,h_-10_d,l_-10_d,c_-10_d,...], [...,v_-10_d,...]\n",
    "        '''\n",
    "        volume_cols = [col for col in df.columns if 'v_' in col]\n",
    "        return np.array(df.drop(volume_cols, 1)), np.array(df[volume_cols])\n",
    "\n",
    "    def combine_price_volume(self, X_price, X_volume):\n",
    "        X_combined = X_price\n",
    "        if len(X_volume[0]) != 0:\n",
    "            for i in range(len(X_volume[0]) - 1, -1, -1):\n",
    "                X_combined = np.insert(X_combined, (i + 1) * (self.paras.n_features - 1), X_volume[:, i], axis=1)\n",
    "\n",
    "        return X_combined\n",
    "\n",
    "    def reshape_input(self, X, y):\n",
    "        '''\n",
    "        X.shape = [n_sample, window_len*n_features]\n",
    "        X_reshaped = [n_sample, window_len, n_features]\n",
    "        '''\n",
    "        n_sample = X.shape[0]\n",
    "        n_channel = int(self.paras.n_features)\n",
    "        n_features_per_channel = int(X.shape[1] / n_channel)\n",
    "        X_reshaped = np.reshape(X, (n_sample, n_features_per_channel, n_channel))\n",
    "        y_reshaped = np.reshape(y, (n_sample, -1))\n",
    "        return X_reshaped, y_reshaped\n",
    "\n",
    "    def build_LSTM_model(self):\n",
    "        model_lstm = Sequential()\n",
    "        first = True\n",
    "        for idx in range(len(self.paras.model['hidden_layers'])):\n",
    "            if idx == (len(self.paras.model['hidden_layers']) - 1):\n",
    "                model_lstm.add(LSTM(int(self.paras.model['hidden_layers'][idx]), return_sequences=False))\n",
    "                model_lstm.add(Activation(self.paras.model['activation'][idx]))\n",
    "                model_lstm.add(Dropout(self.paras.model['dropout'][idx]))\n",
    "            elif first == True:\n",
    "                model_lstm.add(LSTM(input_dim=int(self.paras.n_features),\n",
    "                                    output_dim=int(self.paras.model['hidden_layers'][idx]),\n",
    "                                    return_sequences=True))\n",
    "                model_lstm.add(Activation(self.paras.model['activation'][idx]))\n",
    "                model_lstm.add(Dropout(self.paras.model['dropout'][idx]))\n",
    "                first = False\n",
    "            else:\n",
    "                model_lstm.add(LSTM(int(self.paras.model['hidden_layers'][idx]), return_sequences=True))\n",
    "                model _lstm.add(Activation(self.paras.model['activation'][idx]))\n",
    "                model_lstm.add(Dropout(self.paras.model['dropout'][idx]))\n",
    "\n",
    "        # output layer\n",
    "        model_lstm.add(Dense(output_dim=self.paras.model['out_layer']))\n",
    "        model_lstm.add(Activation(self.paras.model['out_activation']))\n",
    "        model_lstm.compile(loss=self.paras.model['loss'], optimizer=self.paras.model['optimizer'])\n",
    "        print('build LSTM model...')\n",
    "        return model_lstm\n",
    "\n",
    "    def save_training_model(self, model, name):\n",
    "        if self.paras.save == True:\n",
    "            # https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
    "            model.save(self.paras.save_folder + name + '.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "    def append_date_serires(self, df):\n",
    "        append_date = []\n",
    "        append_last_date = df.index[-1]\n",
    "        i = self.paras.pred_len\n",
    "        while i >= 1:\n",
    "            append_last_date = append_last_date + timedelta(days=1)\n",
    "            if append_last_date.isoweekday() > 0 and append_last_date.isoweekday() < 6:\n",
    "                append_date.append(append_last_date)\n",
    "                i -= 1\n",
    "        append_df = pd.DataFrame(index=list(append_date))\n",
    "        df = pd.concat((df, append_df), axis=0)\n",
    "        return df\n",
    "\n",
    "    def plot_training_curve(self, history):\n",
    "        #         %matplotlib inline\n",
    "        #         %pylab inline\n",
    "        #         pylab.rcParams['figure.figsize'] = (15, 9)   # Change the size of plots\n",
    "\n",
    "        # LSTM training\n",
    "        f, ax = plt.subplots()\n",
    "        ax.plot(history.history['loss'])\n",
    "        ax.plot(history.history['val_loss'])\n",
    "        ax.set_title('loss function')\n",
    "        ax.set_ylabel('mse')\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.legend(['loss', 'val_loss'], loc='upper right')\n",
    "        plt.show()\n",
    "        if self.paras.save == True:\n",
    "            w = csv.writer(open(self.paras.save_folder + \"training_curve_model.txt\", \"w\"))\n",
    "            for key, val in history.history.items():\n",
    "                w.writerow([key, val])\n",
    "            for key, val in history.params.items():\n",
    "                w.writerow([key, val])\n",
    "\n",
    "# Regression\n",
    "class rnn_lstm_regression(rnn_lstm):\n",
    "    def __init__(self, paras):\n",
    "        super(rnn_lstm_regression, self).__init__(paras=paras)\n",
    "\n",
    "    def check_parameters(self):\n",
    "        if (self.paras.out_class_type == 'classification' or\n",
    "                    self.paras.model['out_activation'] == 'softmax' or self.paras.model[\n",
    "            'loss'] == 'categorical_crossentropy'):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def GetStockData_PriceVolume(self):\n",
    "        '''\n",
    "        All data is from quandl wiki dataset\n",
    "        Feature set: [Open  High    Low  Close    Volume  Ex-Dividend  Split Ratio Adj. Open  Adj. High  Adj. Low\n",
    "        Adj. Close  Adj. Volume]\n",
    "        '''\n",
    "\n",
    "        # Prepare data frame\n",
    "        stkname = \"WIKI/\" + str(self.paras.ticker)\n",
    "        df = quandl.get(stkname, authtoken='2c24stWyXfdzLVFWxGe4', start_date=self.paras.start_date,\n",
    "                        end_date=self.paras.end_date)\n",
    "        df = df[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]\n",
    "        df = df.rename(columns={\"Adj. Open\": \"open\", \"Adj. High\": \"high\", \"Adj. Low\": \"low\",\n",
    "                                \"Adj. Close\": \"close\", \"Adj. Volume\": \"volume\"})\n",
    "        df_all = df.copy()\n",
    "        df['MA'] = df['close'].rolling(window=self.paras.pred_len, center=False).mean()\n",
    "\n",
    "        # Data frame output\n",
    "        if self.paras.out_type == 'MA':\n",
    "            df['label'] = df['MA'].shift(-1 * self.paras.pred_len)\n",
    "        else:\n",
    "            df['label'] = df['close'].shift(-1 * self.paras.pred_len)\n",
    "\n",
    "        # Generate input features for time series data\n",
    "        featureset = list(['label'])\n",
    "        featuresDict = {'c': 'close', 'h': 'high', 'l': 'low', 'o': 'open', 'v': 'volume'}\n",
    "        for i in range(self.paras.window_len, -1, -1):\n",
    "            for j in list(self.paras.features):\n",
    "                df[j + '_-' + str(i) + '_d'] = df[featuresDict[j]].shift(1 * i)\n",
    "                featureset.append(j + '_-' + str(i) + '_d')\n",
    "\n",
    "        df = df[featureset]\n",
    "        df_lately = df[-self.paras.pred_len:]\n",
    "        df.dropna(inplace=True)\n",
    "        df_valid = df[len(df) - self.paras.valid_len: len(df)]\n",
    "        df = df[0:len(df) - self.paras.valid_len]\n",
    "\n",
    "        return df, df_valid, df_lately, df_all\n",
    "\n",
    "    def preprocessing_data(self, df, featureDropForTraining, with_label_proc=True):\n",
    "        '''\n",
    "        df: pd.DataFrame\n",
    "        X: np.array\n",
    "        y: np.array\n",
    "        convert df into X,y\n",
    "        '''\n",
    "        y = np.array(df['label'])\n",
    "        X_price, X_volume = self.divide_into_price_volume(df.drop(featureDropForTraining, 1))\n",
    "\n",
    "        X_price, scaler_price = self.preprocessing_data_by_row(X_price)\n",
    "        X_volume, scaler_volume = self.preprocessing_data_by_row(X_volume)\n",
    "\n",
    "        # combine price and volume - rearrange\n",
    "        # [...,o_-10_d,h_-10_d,l_-10_d,c_-10_d,...], [...,v_-10_d,...] -> [..., o_-10_d,h_-10_d,l_-10_d,c_-10_d,v_-10_d,...]\n",
    "        X_combined = self.combine_price_volume(X_price, X_volume)\n",
    "\n",
    "        if with_label_proc == True:\n",
    "            y_normalized = scaler_price.transform(y.reshape(1, -1))\n",
    "            y_normalized_T = y_normalized.reshape(-1, 1)\n",
    "        else:\n",
    "            y_normalized_T = np.repeat(float('nan'), len(y))\n",
    "\n",
    "        scaler_combined = {'price': scaler_price, 'volume': scaler_volume}\n",
    "        return X_combined, y_normalized_T, scaler_combined\n",
    "\n",
    "    def LSTM_model_predict(self, model, X, y, scaler=None):\n",
    "        predictions = model.predict(X)\n",
    "        mse_scaled = np.mean((y - predictions) ** 2)\n",
    "        print('scaled data mse: ', mse_scaled)\n",
    "\n",
    "        if scaler != None:\n",
    "            arr = np.array(scaler.inverse_transform(y.reshape(y.shape[0], )))\n",
    "            arr2 = np.array(scaler.inverse_transform(predictions.reshape(predictions.shape[0], )))\n",
    "            return mse_scaled, arr, arr2\n",
    "        return mse_scaled, None, None\n",
    "\n",
    "    def save_data_frame_mse(self, df, mses):\n",
    "        df['actual'] = df['actual']\n",
    "        df['pred'] = df['pred']\n",
    "        df = df.rename(columns={\"actual\": \"a_+\" + str(self.paras.pred_len) + '_d',\n",
    "                                \"pred\": \"p_+\" + str(self.paras.pred_len) + '_d'})\n",
    "\n",
    "        df['a_+' + str(self.paras.pred_len) + '_d_diff'] = df[\"a_+\" + str(self.paras.pred_len) + '_d'] - df['close']\n",
    "        df['p_+' + str(self.paras.pred_len) + '_d_diff'] = df[\"p_+\" + str(self.paras.pred_len) + '_d'] - df['close']\n",
    "        new_list = [\"a_+\" + str(self.paras.pred_len) + '_d', \"p_+\" + str(self.paras.pred_len) + '_d',\n",
    "                    'a_+' + str(self.paras.pred_len) + '_d_diff', 'p_+' + str(self.paras.pred_len) + '_d_diff']\n",
    "\n",
    "        default_list = ['open', 'high', 'low', 'close', 'volume']\n",
    "        original_other_list = set(df.columns) - set(default_list) - set(new_list)\n",
    "        original_other_list = list(original_other_list)\n",
    "        df = df[default_list + original_other_list + new_list]\n",
    "        model_acc = mses[1] / mses[0]\n",
    "        if self.paras.save == True:\n",
    "            df.to_csv(self.paras.save_folder + self.paras.ticker + ('_%.2f' % model_acc) + \"_data_frame.csv\")\n",
    "            with open(self.paras.save_folder + 'parameters.txt', \"w\") as text_file:\n",
    "                text_file.write(self.paras.__str__())\n",
    "                text_file.write(str(mses[0]) + '\\n')\n",
    "                text_file.write(str(mses[1]) + '\\n')\n",
    "        return df\n",
    "\n",
    "    def run(self):\n",
    "        if self.check_parameters() == False:\n",
    "            raise IndexError('Parameters for LSTM is wrong, check out_class_type')\n",
    "\n",
    "        ##############################f##################################################\n",
    "        self.paras.save_folder = self.get_save_directory()\n",
    "        print('Save Directory: ', self.paras.save_folder)\n",
    "        ################################################################################\n",
    "\n",
    "        featureDropForTraining = ['label']\n",
    "\n",
    "        # get data\n",
    "        df, df_valid, df_lately, df_all = self.GetStockData_PriceVolume()\n",
    "        print('df len:', len(df))\n",
    "        print('df_valid len:', len(df_valid))\n",
    "        print('df_lately len:', len(df_lately))\n",
    "        print('df_all len:', len(df_all))\n",
    "\n",
    "        # preprocessing\n",
    "        X, y, scaler = self.preprocessing_data(df, featureDropForTraining, with_label_proc=True)\n",
    "        X_valid, y_valid, scaler_valid = self.preprocessing_data(df_valid, featureDropForTraining, with_label_proc=True)\n",
    "        X_lately, y_lately, scaler_lately = self.preprocessing_data(df_lately, featureDropForTraining,\n",
    "                                                                    with_label_proc=False)\n",
    "\n",
    "        # cross validation\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        print('Train shape X:', X_train.shape, ',y:', y_train.shape)\n",
    "        print('Test shape X:', X_test.shape, ',y:', y_test.shape)\n",
    "\n",
    "        # reshape input data to LSTM model\n",
    "        X, y = self.reshape_input(X, y)\n",
    "        X_train, y_train = self.reshape_input(X_train, y_train)\n",
    "        X_test, y_test = self.reshape_input(X_test, y_test)\n",
    "        X_valid, y_valid = self.reshape_input(X_valid, y_valid)\n",
    "        X_lately, y_lately = self.reshape_input(X_lately, y_lately)\n",
    "        print('After reshape X_train shape:', X_train.shape)\n",
    "        print('After reshape y_train shape:', y_train.shape)\n",
    "\n",
    "        # build LSTM model\n",
    "        history = History()\n",
    "        model_lstm = self.build_LSTM_model()\n",
    "        model_lstm.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            batch_size=self.paras.batch_size,\n",
    "            nb_epoch=self.paras.epoch,\n",
    "            validation_split=self.paras.validation_split,\n",
    "            # validation_data = (X_known_lately, y_known_lately),\n",
    "            callbacks=[history],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # save model\n",
    "        self.save_training_model(model_lstm, 'lstm_model')\n",
    "\n",
    "        # validation test + known lately data\n",
    "        print(' ############## validation on test data ############## ')\n",
    "        mse_test, tmp, tmp2 = self.LSTM_model_predict(model_lstm, X_test, y_test)\n",
    "\n",
    "        print(' ############## validation on train/test lately data ############## ')\n",
    "        mse_traintest, tmp, tmp2 = self.LSTM_model_predict(model_lstm, X[-self.paras.valid_len:],\n",
    "                                                           y[-self.paras.valid_len:])\n",
    "\n",
    "        print(' ############## validation on valid data ############## ')\n",
    "        mse_known_lately, df_all.loc[df_valid.index, 'actual'], df_all.loc[\n",
    "            df_valid.index, 'pred'] = self.LSTM_model_predict(model_lstm, X_valid, y_valid,\n",
    "                                                              scaler=scaler_valid['price'])\n",
    "\n",
    "        # predict lately data\n",
    "        print(' ############## validation on lately data ############## ')\n",
    "        mse_lately, df_all.loc[df_lately.index, 'actual'], df_all.loc[\n",
    "            df_lately.index, 'pred'] = self.LSTM_model_predict(model_lstm, X_lately, y_lately,\n",
    "                                                               scaler=scaler_lately['price'])\n",
    "\n",
    "        # rewrite data frame and save / update\n",
    "        df_all = self.save_data_frame_mse(df_all, mses=[mse_test, mse_known_lately])\n",
    "        self.df = df_all\n",
    "\n",
    "        # plot training loss/ validation loss\n",
    "        self.plot_training_curve(history)\n",
    "\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        print(df_all[-(self.paras.pred_len + self.paras.valid_len):])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
