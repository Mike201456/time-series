{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mLSTM_stock01.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mREADME.md\u001b[0m*\r\n",
      "\u001b[01;32mScrapYahooKeyStat.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mStock_Prediction_General_Method.py\u001b[0m*\r\n",
      "\u001b[01;32mStock_Prediction_Global_Parameters.py\u001b[0m*\r\n",
      "\u001b[01;32mStock_Prediction_Stateless_LSTM_Model.py\u001b[0m*\r\n",
      "\u001b[01;32mStock_Prediction_Stateless_LSTM_Model_01.py\u001b[0m*\r\n",
      "\u001b[01;32mStock_Prediction_Stateless_LSTM_Model_02.py\u001b[0m*\r\n",
      "\u001b[01;32mStock_Prediction_Stateless_LSTM_Run.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mStock_Prediction_Stateless_LSTM_Run.py\u001b[0m*\r\n",
      "Untitled.ipynb\r\n",
      "\u001b[01;34m__pycache__\u001b[0m/\r\n",
      "\u001b[01;34mhistory\u001b[0m/\r\n",
      "multiple_input_features-Copy1.ipynb\r\n",
      "\u001b[01;32mstock_model.ipynb\u001b[0m*\r\n",
      "stock_prediction .ipynb\r\n",
      "time-series_README.pdf\r\n",
      "\u001b[01;32mworking_on.ipynb\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM for international airline passengers problem with regression framing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas import read_csv\n",
    "import pandas as pd \n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import quandl \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), :]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "stkname = \"WIKI/\" + str(ticker)\n",
    "        # df = quandl.get(stkname, authtoken='2c24stWyXfdzLVFWxGe4', start_date=self.paras.start_date,\n",
    "        #                 end_date=self.paras.end_date)\n",
    "        # df = df[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]\n",
    "        # df = df.rename(columns={\"Adj. Open\": \"open\", \"Adj. High\": \"high\", \"Adj. Low\": \"low\",\n",
    "        #                         \"Adj. Close\": \"close\", \"Adj. Volume\": \"volume\"})\n",
    "\n",
    "        ### add more data from here \n",
    "\n",
    "        # get data for stock price \n",
    "df01 = quandl.get(stkname, authtoken='2c24stWyXfdzLVFWxGe4', start_date= '1980-01-01',\n",
    "                            end_date='2017-10-09')\n",
    "df01 = df01[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]\n",
    "df01 = df01.rename(columns={\"Adj. Open\": \"open\", \"Adj. High\": \"high\", \"Adj. Low\": \"low\",\n",
    "                                \"Adj. Close\": \"close\", \"Adj. Volume\": \"volume\"})\n",
    "df01['date'] = df01.index\n",
    "        \n",
    "ref_tks = ['AMZN', 'GOOGL']\n",
    "\n",
    "d = []\n",
    "for i in ref_tks:\n",
    "    stkname = \"WIKI/\" + str(i)\n",
    "    t = quandl.get(stkname, authtoken='2c24stWyXfdzLVFWxGe4', start_date= '1980-01-01',\n",
    "                                    end_date='2017-10-09')\n",
    "\n",
    "    t = t[[ 'Adj. Close']]\n",
    "    t = t.rename(columns={\"Adj. Close\": str(i) + '_'+ \"close\"})\n",
    "    t['date'] = t.index\n",
    "    d.append(t)\n",
    "df_ref = pd.concat(d, axis = 1)\n",
    "        # get data for VIX \n",
    "\n",
    "        # df_vix_1 = quandl.get(\"CHRIS/CBOE_VX1\", authtoken=\"-Cd2GkPqwZYD7_NNFF4K\")\n",
    "        # df_vix_1['date'] = df_vix_1.index\n",
    "\n",
    "\n",
    "df = pd.concat([df01, df_ref], axis = 1, join = 'inner')\n",
    "df = df[['open', 'high', 'low', 'close', 'volume', 'AMZN_close', 'GOOGL_close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'volume', 'AMZN_close', 'GOOGL_close'], dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all parameters \n",
    "\n",
    "pred_len = 10 \n",
    "valid_len = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to divide X into price and volume \n",
    "def divide_into_price_volume(df):\n",
    "\n",
    "    #volume_cols = [col for col in df.columns if 'v' in col]\n",
    "    return np.array(df.drop(df['volume'], 1)), np.array(df['volume'])\n",
    "\n",
    "\n",
    "# preprocess data by row \n",
    "\n",
    "def preprocessing_data_by_row(data):\n",
    "        '''\n",
    "        data: N*M np.array\n",
    "        N: sample\n",
    "        M: features\n",
    "        data_T: M*N\n",
    "        data_T_scale: scaler for column by column, M*N\n",
    "        data_T_scale_T: N*M\n",
    "        '''\n",
    "        if data.size == 0:\n",
    "            return data, None\n",
    "\n",
    "        data_T = data.transpose()\n",
    "        \n",
    "        scaler = preprocessing.MinMaxScaler().fit(data_T)\n",
    "        \n",
    "        data_T_scale = scaler.transform(data_T)\n",
    "        data_T_scale_T = data_T_scale.transpose()\n",
    "        return data_T_scale_T, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['close'].shift(-1 * pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "X = df.drop('label', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>AMZN_close</th>\n",
       "      <th>GOOGL_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-19</th>\n",
       "      <td>2.024737</td>\n",
       "      <td>2.047227</td>\n",
       "      <td>1.950842</td>\n",
       "      <td>1.973332</td>\n",
       "      <td>97230000.0</td>\n",
       "      <td>38.63</td>\n",
       "      <td>50.322842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-20</th>\n",
       "      <td>1.973332</td>\n",
       "      <td>1.991323</td>\n",
       "      <td>1.959195</td>\n",
       "      <td>1.979115</td>\n",
       "      <td>79195200.0</td>\n",
       "      <td>39.51</td>\n",
       "      <td>54.322689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-23</th>\n",
       "      <td>1.982970</td>\n",
       "      <td>2.009315</td>\n",
       "      <td>1.966263</td>\n",
       "      <td>1.997107</td>\n",
       "      <td>63665000.0</td>\n",
       "      <td>39.45</td>\n",
       "      <td>54.869377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-24</th>\n",
       "      <td>2.008673</td>\n",
       "      <td>2.053010</td>\n",
       "      <td>2.004175</td>\n",
       "      <td>2.053010</td>\n",
       "      <td>93534000.0</td>\n",
       "      <td>39.05</td>\n",
       "      <td>52.597363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-25</th>\n",
       "      <td>2.050440</td>\n",
       "      <td>2.130119</td>\n",
       "      <td>2.038874</td>\n",
       "      <td>2.123693</td>\n",
       "      <td>126404600.0</td>\n",
       "      <td>40.30</td>\n",
       "      <td>53.164113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open      high       low     close       volume  AMZN_close  \\\n",
       "Date                                                                          \n",
       "2004-08-19  2.024737  2.047227  1.950842  1.973332   97230000.0       38.63   \n",
       "2004-08-20  1.973332  1.991323  1.959195  1.979115   79195200.0       39.51   \n",
       "2004-08-23  1.982970  2.009315  1.966263  1.997107   63665000.0       39.45   \n",
       "2004-08-24  2.008673  2.053010  2.004175  2.053010   93534000.0       39.05   \n",
       "2004-08-25  2.050440  2.130119  2.038874  2.123693  126404600.0       40.30   \n",
       "\n",
       "            GOOGL_close  \n",
       "Date                     \n",
       "2004-08-19    50.322842  \n",
       "2004-08-20    54.322689  \n",
       "2004-08-23    54.869377  \n",
       "2004-08-24    52.597363  \n",
       "2004-08-25    53.164113  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 97230000.  79195200.  63665000. ...,  19198189.  19029621.  25015218.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-25ed53d57736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_volume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_data_by_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_price\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_volume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_data_by_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_volume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#X_combined =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-239-0193c1083470>\u001b[0m in \u001b[0;36mpreprocessing_data_by_row\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdata_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdata_T_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         X = check_array(X, copy=self.copy, warn_on_dtype=True,\n\u001b[0;32m--> 334\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 97230000.  79195200.  63665000. ...,  19198189.  19029621.  25015218.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "X_price, X_volume = X.drop('volume', 1), X['volume']\n",
    "X_price, scaler_price = preprocessing_data_by_row(X_price)\n",
    "X_volume, scaler_volume = preprocessing_data_by_row(X_volume)\n",
    "#X_combined = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(x):\n",
    "    return x[:int(0.7*len(x))], x[int(0.7*len(x))+1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X)\n",
    "y_train, y_test = train_test_split(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels [ 97230000.  79195200.  63665000. ...,  79239300.  59305400.  57010100.] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-f0cef4ab4227>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_volume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivide_into_price_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_volume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivide_into_price_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-239-0193c1083470>\u001b[0m in \u001b[0;36mdivide_into_price_volume\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#volume_cols = [col for col in df.columns if 'v' in col]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels [ 97230000.  79195200.  63665000. ...,  79239300.  59305400.  57010100.] not contained in axis"
     ]
    }
   ],
   "source": [
    "# X_train_price, X_train_volume = divide_into_price_volume(X_train)\n",
    "# X_test_price, X_test_volume = divide_into_price_volume(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 97230000.  79195200.  63665000. ...,  64717100.  78073100.  72729300.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-140cd3773bf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_train_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_data_by_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_price\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_traini_volume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_data_by_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_volume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-239-0193c1083470>\u001b[0m in \u001b[0;36mpreprocessing_data_by_row\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdata_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdata_T_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         X = check_array(X, copy=self.copy, warn_on_dtype=True,\n\u001b[0;32m--> 334\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 97230000.  79195200.  63665000. ...,  64717100.  78073100.  72729300.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "X_price, scaler_price = preprocessing_data_by_row(X_price)\n",
    "X_volume, scaler_volume = preprocessing_data_by_row(X_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_price, X_train_volume = divide_into_price_volume(X_train)\n",
    "# X_test_price, X_test_volume = divide_into_price_volume(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       ..., \n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_price, scaler_price = preprocessing_data_by_row(X_price)\n",
    "X_volume, scaler_volume = preprocessing_data_by_row(X_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5b70aa8ac8>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b70a73550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_price[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 10 \n",
    "features = 'ohlcvag'\n",
    "featureset = []\n",
    "featuresDict = {'c': 'close', 'h': 'high', 'l': 'low', 'o': 'open', 'v': 'volume', 'a': 'AMZN_close', 'g':'GOOGL_close'}\n",
    "\n",
    "for i in range(window_len, -1, -1):\n",
    "    for j in list(features):\n",
    "        df[j + '_-' + str(i) + '_d'] = df[featuresDict[j]].shift(1 * i)\n",
    "        featureset.append(j + '_-' + str(i) + '_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[featureset]\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_lately = df[-pred_len:]\n",
    "valid = df[len(df) - valid_len: len(df)]\n",
    "train = df[0:len(df) - valid_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o_-10_d</th>\n",
       "      <th>h_-10_d</th>\n",
       "      <th>l_-10_d</th>\n",
       "      <th>c_-10_d</th>\n",
       "      <th>v_-10_d</th>\n",
       "      <th>a_-10_d</th>\n",
       "      <th>g_-10_d</th>\n",
       "      <th>o_-9_d</th>\n",
       "      <th>h_-9_d</th>\n",
       "      <th>l_-9_d</th>\n",
       "      <th>...</th>\n",
       "      <th>v_-1_d</th>\n",
       "      <th>a_-1_d</th>\n",
       "      <th>g_-1_d</th>\n",
       "      <th>o_-0_d</th>\n",
       "      <th>h_-0_d</th>\n",
       "      <th>l_-0_d</th>\n",
       "      <th>c_-0_d</th>\n",
       "      <th>v_-0_d</th>\n",
       "      <th>a_-0_d</th>\n",
       "      <th>g_-0_d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-02</th>\n",
       "      <td>2.024737</td>\n",
       "      <td>2.047227</td>\n",
       "      <td>1.950842</td>\n",
       "      <td>1.973332</td>\n",
       "      <td>97230000.0</td>\n",
       "      <td>38.63</td>\n",
       "      <td>50.322842</td>\n",
       "      <td>1.973332</td>\n",
       "      <td>1.991323</td>\n",
       "      <td>1.959195</td>\n",
       "      <td>...</td>\n",
       "      <td>128931600.0</td>\n",
       "      <td>38.24</td>\n",
       "      <td>50.280210</td>\n",
       "      <td>2.281122</td>\n",
       "      <td>2.301042</td>\n",
       "      <td>2.238070</td>\n",
       "      <td>2.291404</td>\n",
       "      <td>101581200.0</td>\n",
       "      <td>39.18</td>\n",
       "      <td>50.912161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-03</th>\n",
       "      <td>1.973332</td>\n",
       "      <td>1.991323</td>\n",
       "      <td>1.959195</td>\n",
       "      <td>1.979115</td>\n",
       "      <td>79195200.0</td>\n",
       "      <td>39.51</td>\n",
       "      <td>54.322689</td>\n",
       "      <td>1.982970</td>\n",
       "      <td>2.009315</td>\n",
       "      <td>1.966263</td>\n",
       "      <td>...</td>\n",
       "      <td>101581200.0</td>\n",
       "      <td>39.18</td>\n",
       "      <td>50.912161</td>\n",
       "      <td>2.250922</td>\n",
       "      <td>2.308110</td>\n",
       "      <td>2.249636</td>\n",
       "      <td>2.263773</td>\n",
       "      <td>73367000.0</td>\n",
       "      <td>38.74</td>\n",
       "      <td>50.159839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-07</th>\n",
       "      <td>1.982970</td>\n",
       "      <td>2.009315</td>\n",
       "      <td>1.966263</td>\n",
       "      <td>1.997107</td>\n",
       "      <td>63665000.0</td>\n",
       "      <td>39.45</td>\n",
       "      <td>54.869377</td>\n",
       "      <td>2.008673</td>\n",
       "      <td>2.053010</td>\n",
       "      <td>2.004175</td>\n",
       "      <td>...</td>\n",
       "      <td>73367000.0</td>\n",
       "      <td>38.74</td>\n",
       "      <td>50.159839</td>\n",
       "      <td>2.274697</td>\n",
       "      <td>2.325460</td>\n",
       "      <td>2.263773</td>\n",
       "      <td>2.297829</td>\n",
       "      <td>75489400.0</td>\n",
       "      <td>38.51</td>\n",
       "      <td>50.947269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-08</th>\n",
       "      <td>2.008673</td>\n",
       "      <td>2.053010</td>\n",
       "      <td>2.004175</td>\n",
       "      <td>2.053010</td>\n",
       "      <td>93534000.0</td>\n",
       "      <td>39.05</td>\n",
       "      <td>52.597363</td>\n",
       "      <td>2.050440</td>\n",
       "      <td>2.130119</td>\n",
       "      <td>2.038874</td>\n",
       "      <td>...</td>\n",
       "      <td>75489400.0</td>\n",
       "      <td>38.51</td>\n",
       "      <td>50.947269</td>\n",
       "      <td>2.293974</td>\n",
       "      <td>2.349877</td>\n",
       "      <td>2.292689</td>\n",
       "      <td>2.335741</td>\n",
       "      <td>85881600.0</td>\n",
       "      <td>38.01</td>\n",
       "      <td>51.308384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-09</th>\n",
       "      <td>2.050440</td>\n",
       "      <td>2.130119</td>\n",
       "      <td>2.038874</td>\n",
       "      <td>2.123693</td>\n",
       "      <td>126404600.0</td>\n",
       "      <td>40.30</td>\n",
       "      <td>53.164113</td>\n",
       "      <td>2.126263</td>\n",
       "      <td>2.260560</td>\n",
       "      <td>2.103773</td>\n",
       "      <td>...</td>\n",
       "      <td>85881600.0</td>\n",
       "      <td>38.01</td>\n",
       "      <td>51.308384</td>\n",
       "      <td>2.319677</td>\n",
       "      <td>2.332528</td>\n",
       "      <td>2.266986</td>\n",
       "      <td>2.293974</td>\n",
       "      <td>115334800.0</td>\n",
       "      <td>38.07</td>\n",
       "      <td>51.313400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             o_-10_d   h_-10_d   l_-10_d   c_-10_d      v_-10_d  a_-10_d  \\\n",
       "Date                                                                       \n",
       "2004-09-02  2.024737  2.047227  1.950842  1.973332   97230000.0    38.63   \n",
       "2004-09-03  1.973332  1.991323  1.959195  1.979115   79195200.0    39.51   \n",
       "2004-09-07  1.982970  2.009315  1.966263  1.997107   63665000.0    39.45   \n",
       "2004-09-08  2.008673  2.053010  2.004175  2.053010   93534000.0    39.05   \n",
       "2004-09-09  2.050440  2.130119  2.038874  2.123693  126404600.0    40.30   \n",
       "\n",
       "              g_-10_d    o_-9_d    h_-9_d    l_-9_d    ...           v_-1_d  \\\n",
       "Date                                                   ...                    \n",
       "2004-09-02  50.322842  1.973332  1.991323  1.959195    ...      128931600.0   \n",
       "2004-09-03  54.322689  1.982970  2.009315  1.966263    ...      101581200.0   \n",
       "2004-09-07  54.869377  2.008673  2.053010  2.004175    ...       73367000.0   \n",
       "2004-09-08  52.597363  2.050440  2.130119  2.038874    ...       75489400.0   \n",
       "2004-09-09  53.164113  2.126263  2.260560  2.103773    ...       85881600.0   \n",
       "\n",
       "            a_-1_d     g_-1_d    o_-0_d    h_-0_d    l_-0_d    c_-0_d  \\\n",
       "Date                                                                    \n",
       "2004-09-02   38.24  50.280210  2.281122  2.301042  2.238070  2.291404   \n",
       "2004-09-03   39.18  50.912161  2.250922  2.308110  2.249636  2.263773   \n",
       "2004-09-07   38.74  50.159839  2.274697  2.325460  2.263773  2.297829   \n",
       "2004-09-08   38.51  50.947269  2.293974  2.349877  2.292689  2.335741   \n",
       "2004-09-09   38.01  51.308384  2.319677  2.332528  2.266986  2.293974   \n",
       "\n",
       "                 v_-0_d  a_-0_d     g_-0_d  \n",
       "Date                                        \n",
       "2004-09-02  101581200.0   39.18  50.912161  \n",
       "2004-09-03   73367000.0   38.74  50.159839  \n",
       "2004-09-07   75489400.0   38.51  50.947269  \n",
       "2004-09-08   85881600.0   38.01  51.308384  \n",
       "2004-09-09  115334800.0   38.07  51.313400  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_y = train['close']\n",
    "# #train_X = train.drop(train['close'], 1)\n",
    "# train_y\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.36882605, -0.36882605, -0.36882605, ...,  2.08557202,\n",
       "         -0.36882515, -0.36882487],\n",
       "        [-0.36601593, -0.36601593, -0.36601593, ...,  1.42962175,\n",
       "         -0.36601503, -0.36601475],\n",
       "        [-0.36549624, -0.36549624, -0.36549624, ...,  1.48541988,\n",
       "         -0.36549534, -0.36549504],\n",
       "        ..., \n",
       "        [-0.40397498, -0.40397497, -0.4039751 , ...,  2.20244175,\n",
       "         -0.40395385, -0.40394736],\n",
       "        [-0.39913444, -0.3991344 , -0.3991345 , ...,  1.15100184,\n",
       "         -0.39911202, -0.39910559],\n",
       "        [-0.39556288, -0.39556285, -0.39556313, ...,  1.32130041,\n",
       "         -0.39554001, -0.39553303]]),\n",
       " StandardScaler(copy=True, with_mean=True, with_std=True))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5d4a7feea56e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# normalize the dataset\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = `scaler.fit_transform(dataset)\n",
    "\n",
    "dataset.shape\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# train = dataset[0:train_size,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 5\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(5, 4), kernel_regularizer=regularizers.l2(1),\n",
    "                activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=2, batch_size=1000, verbose=2)\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # invert predictions\n",
    "# trainPredict = scaler.inverse_transform(trainPredict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "date = pd.to_datetime(df.Date)\n",
    "plt.figure(figsize = (20, 5))\n",
    "plt.plot(date, scaler.inverse_transform(dataset), color = 'r')\n",
    "plt.plot(date[:len(trainPredictPlot)+1], trainPredictPlot, color = 'g')\n",
    "plt.plot(date[:len(testPredictPlot)+1], testPredictPlot, color = 'b')\n",
    "plt.xlim(('2017-08-01', '2017-09-28'))\n",
    "plt.ylim((150, 165))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
